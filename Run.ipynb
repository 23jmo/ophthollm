{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf763154-0785-407d-8a4f-ab500519ca19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/opthollm\n",
      "/home/jupyter/opthollm/MiniGPT-4\n",
      "Initializing Chat\n",
      "Loading VIT\n",
      "Loading VIT Done\n",
      "Loading Q-Former\n",
      "Loading Q-Former Done\n",
      "Loading LLAMA\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [04:19<00:00, 86.60s/it]\n",
      "Loading LLAMA Done\n",
      "Load 4 training prompts\n",
      "Prompt Example \n",
      "###Human: <Img><ImageHere></Img> Describe this image in detail. ###Assistant: \n",
      "Load BLIP2-LLM Checkpoint: pretrained_minigpt4.pth\n",
      "Initialization Finished\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/components.py:164: UserWarning: Unknown style parameter: rows\n",
      "  warnings.warn(f\"Unknown style parameter: {key}\")\n",
      "/opt/conda/lib/python3.10/site-packages/gradio/components.py:164: UserWarning: Unknown style parameter: object_fit\n",
      "  warnings.warn(f\"Unknown style parameter: {key}\")\n",
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://7299f4392b82be04f1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n",
      "^C\n",
      "Keyboard interruption in main thread... closing server.\n",
      "Killing tunnel 127.0.0.1:7860 <> https://7299f4392b82be04f1.gradio.live\n"
     ]
    }
   ],
   "source": [
    "%cd opthollm/\n",
    "%cd MiniGPT-4/\n",
    "!python demo.py --cfg-path eval_configs/minigpt4_eval.yaml --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e051be2-c82b-4de6-ab54-763799c5c87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'opthollm/'\n",
      "/home/jupyter/opthollm\n",
      "/home/jupyter/opthollm/MiniGPT-4\n",
      "Initializing Chat\n",
      "Loading VIT\n",
      "Loading VIT Done\n",
      "Loading Q-Former\n",
      "Loading Q-Former Done\n",
      "Loading LLAMA\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [04:07<00:00, 82.39s/it]\n",
      "Loading LLAMA Done\n",
      "Load 4 training prompts\n",
      "Prompt Example \n",
      "###Human: <Img><ImageHere></Img> Could you describe the contents of this image for me? ###Assistant: \n",
      "Load BLIP2-LLM Checkpoint: pretrained_minigpt4.pth\n",
      "Initialization Finished\n",
      "Please enter the image path or URL (press Enter for plain text conversation): ^C\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/jupyter/opthollm/MiniGPT-4/\u001b[0m\u001b[1;33mcli_demo.py\u001b[0m:\u001b[94m76\u001b[0m in \u001b[92m<module>\u001b[0m                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m args.english:                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 74 \u001b[0m\u001b[2m│   │   \u001b[0mimage_path = \u001b[96minput\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33m请输入图像路径或URL（回车进入纯文本对话） \u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 76 \u001b[2m│   │   \u001b[0mimage_path = \u001b[96minput\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mPlease enter the image path or URL (press \u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 78 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m image_path == \u001b[33m'\u001b[0m\u001b[33mstop\u001b[0m\u001b[33m'\u001b[0m:                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 79 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%cd opthollm/\n",
    "%cd MiniGPT-4/\n",
    "!python cli_demo.py --cfg-path eval_configs/minigpt4_eval.yaml --gpu-id 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ab52c-3461-4edf-ada8-226673119dbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
