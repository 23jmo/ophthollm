{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd MiniGPT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Packages\n",
    "Import minigpt4 and necessary helper libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import gradio as gr\n",
    "\n",
    "from minigpt4.common.config import Config\n",
    "from minigpt4.common.dist_utils import get_rank\n",
    "from minigpt4.common.registry import registry\n",
    "from minigpt4.conversation.conversation import Chat, CONV_VISION\n",
    "\n",
    "# imports modules for registration\n",
    "from minigpt4.datasets.builders import *\n",
    "from minigpt4.models import *\n",
    "from minigpt4.processors import *\n",
    "from minigpt4.runners import *\n",
    "from minigpt4.tasks import *\n",
    "import os\n",
    "\n",
    "import argparse as argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods\n",
    "Define helper methods including encode diagnosis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Methods\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Demo\")\n",
    "    parser.add_argument(\"--cfg-path\", required=True, help=\"path to configuration file.\")\n",
    "    parser.add_argument(\"--gpu-id\", type=int, default=0, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--num-beams\", type=int, default=2, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--temperature\", type=int, default=0.9, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--english\", type=bool, default=True, help=\"chinese or english\")\n",
    "    parser.add_argument(\"--prompt-en\", type=str, default=\"can you describe the current picture?\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\"--prompt-zh\", type=str, default=\"你能描述一下当前的图片？\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\n",
    "        \"--options\",\n",
    "        nargs=\"+\",\n",
    "        help=\"override some settings in the used config, the key-value pair \"\n",
    "        \"in xxx=yyy format will be merged into config file (deprecate), \"\n",
    "        \"change to --cfg-options instead.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def setup_seeds(config):\n",
    "    seed = config.run_cfg.seed + get_rank()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "\n",
    "### fix this method since it's not completely accurate \n",
    "\n",
    "# determines if the LLM thinks the image is glaucomatous or not based on whether or not the text contains glaucomatous or not \n",
    "def encode_diagnosis(diagnosis):\n",
    "    # could add: if contains glaucomatous and normal, then only look at first sentence\n",
    "    \n",
    "    if 'glaucomatous' in diagnosis.lower():\n",
    "        return 1\n",
    "    if 'normal' in diagnosis.lower():\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "# finds the true label of an image based on where it's stored in file path \n",
    "def fetch_ground_truth(img_path):\n",
    "    split_string = img_path.split(\"/\")\n",
    "\n",
    "    # Find the index of \"glaucoma\" in the split string\n",
    "    try:\n",
    "        split_string.index(\"glaucoma\")\n",
    "        return 1\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# helper method that gets all files from a directory \n",
    "def get_all_files(directory):\n",
    "    all_files = []\n",
    "    \n",
    "    # Iterate over all the directories and files within the given directory\n",
    "    for root, directories, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            all_files.append(file_path)\n",
    "    \n",
    "    return all_files\n",
    "\n",
    "def get_random_file(directory):\n",
    "    all_files = get_all_files(directory)\n",
    "    return random.choice(all_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initializing Chat')\n",
    "#args = parse_args()\n",
    "#args = preset_args\n",
    "args = argparse.Namespace(cfg_path='eval_configs/minigpt4_eval.yaml', gpu_id=0, num_beams=2, temperature=0.9, english=True, prompt_en='can you describe the current picture?', prompt_zh='你能描述一下当前的图片？', options=None)\n",
    "cfg = Config(args)\n",
    "\n",
    "model_config = cfg.model_cfg\n",
    "model_config.device_8bit = args.gpu_id\n",
    "model_cls = registry.get_model_class(model_config.arch)\n",
    "model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))\n",
    "\n",
    "vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train\n",
    "vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)\n",
    "chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id))\n",
    "print('Initialization Finished')\n",
    "\n",
    "print('Intializing Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Few Shot Learning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store output\n",
    "\n",
    "few_shot_data = {'img_path:': [],\n",
    "                 'prediction:': [],\n",
    "                 'ground_truth:': [],\n",
    "                 'llm_message': []\n",
    "                 }\n",
    "\n",
    "# define examples for few shot learning\n",
    "\n",
    "import image_descriptions\n",
    "examples = image_descriptions.chain_of_thought_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'RIM-ONE_DL_images/partitioned_randomly/training_set'\n",
    "# pick random training image to test on\n",
    "\n",
    "img_list = []\n",
    "chat_state = CONV_VISION.copy()\n",
    "\n",
    "image = get_random_file(directory)\n",
    "few_shot_data['img_path:'].append(image)\n",
    "few_shot_data['ground_truth:'].append(fetch_ground_truth(image))\n",
    "\n",
    "\n",
    "\n",
    "# ask the prompt that has multiple examples (few shot inference)\n",
    "\n",
    "chat.embed_imgs(examples)\n",
    "chat.embed_imgs([image])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "\n",
    "<Img><ImageHere></Img>\n",
    "Please diagnose the image as glaucomatous or normal:\n",
    "\n",
    "Diagnosis: {examples[0][1]}\n",
    "\n",
    "<Img><ImageHere></Img>\n",
    "Please diagnose the image as glaucomatous or normal:\n",
    "\n",
    "Diagnosis: {examples[1][1]}\n",
    "\n",
    "<Img><ImageHere></Img>\n",
    "Please diagnose the image as glaucomatous or normal:\n",
    "\n",
    "Diagnosis: {examples[2][1]}\n",
    "\n",
    "<Img><ImageHere></Img>\n",
    "Please diagnose the image as glaucomatous or normal:\n",
    "\n",
    "Diagnosis:\n",
    "\"\"\"\n",
    "\n",
    "# have the model answer and display \n",
    "llm_message = llm_message = chat.answer(\n",
    "        conv=chat_state,\n",
    "        img_list=img_list,\n",
    "        num_beams=args.num_beams,\n",
    "        temperature=args.temperature,\n",
    "        max_new_tokens=300,\n",
    "        max_length=2000\n",
    "    )[0]\n",
    "\n",
    "few_shot_data['llm_message'].append(llm_message)\n",
    "few_shot_data['prediction:'].append(encode_diagnosis(llm_message))\n",
    "\n",
    "print(f\"Img: {image} - Prediction: {few_shot_data['prediction:'][-1]} - Ground Truth: {few_shot_data['ground_truth:'][-1]} - LLM Message: {few_shot_data['llm_message'][-1]}\")\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
