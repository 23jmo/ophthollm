{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2afdb06-51c7-4344-919c-35c1c68dbf6a",
   "metadata": {},
   "source": [
    "# MiniGPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb7fa8e-701a-4031-8051-ecf3afbb652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd MiniGPT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0e340-4138-4ca9-9d05-3629ad0e66a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa89ce9-016c-4138-b326-7f4c1c452a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import gradio as gr\n",
    "\n",
    "from minigpt4.common.config import Config\n",
    "from minigpt4.common.dist_utils import get_rank\n",
    "from minigpt4.common.registry import registry\n",
    "from minigpt4.conversation.multi_img_conversation import Chat, CONV_VISION\n",
    "\n",
    "# imports modules for registration\n",
    "from minigpt4.datasets.builders import *\n",
    "from minigpt4.models import *\n",
    "from minigpt4.processors import *\n",
    "from minigpt4.runners import *\n",
    "from minigpt4.tasks import *\n",
    "import os\n",
    "\n",
    "import argparse as argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f979de-e8ca-46c7-a320-112ddc9cd427",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b0b91-0e31-4233-a9f5-ac7b8d1463a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Helper Methods\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Demo\")\n",
    "    parser.add_argument(\"--cfg-path\", required=True, help=\"path to configuration file.\")\n",
    "    parser.add_argument(\"--gpu-id\", type=int, default=0, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--num-beams\", type=int, default=2, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--temperature\", type=int, default=0.9, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--english\", type=bool, default=True, help=\"chinese or english\")\n",
    "    parser.add_argument(\"--prompt-en\", type=str, default=\"can you describe the current picture?\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\"--prompt-zh\", type=str, default=\"你能描述一下当前的图片？\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\n",
    "        \"--options\",\n",
    "        nargs=\"+\",\n",
    "        help=\"override some settings in the used config, the key-value pair \"\n",
    "        \"in xxx=yyy format will be merged into config file (deprecate), \"\n",
    "        \"change to --cfg-options instead.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def setup_seeds(config):\n",
    "    seed = config.run_cfg.seed + get_rank()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "def ask_model(chat, image, prompt, img_list):\n",
    "    chat.upload_img(image, chat_state, img_list)\n",
    "    chat.ask(prompt, chat_state)\n",
    "    llm_message = chat.answer(\n",
    "        conv=chat_state,\n",
    "        img_list=img_list,\n",
    "        num_beams=args.num_beams,\n",
    "        temperature=args.temperature,\n",
    "        max_new_tokens=300,\n",
    "        max_length=2000\n",
    "    )[0]\n",
    "    return llm_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8309d42-370c-4216-a6f4-19ff74f27c8b",
   "metadata": {},
   "source": [
    "### Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5600ee-fa40-49a8-8bed-69ed8ddeb6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initializing Chat')\n",
    "#args = parse_args()\n",
    "#args = preset_args\n",
    "args = argparse.Namespace(cfg_path='eval_configs/minigpt4_eval.yaml', gpu_id=0, num_beams=2, temperature=0.9, english=True, prompt_en='can you describe the current picture?', prompt_zh='你能描述一下当前的图片？', options=None)\n",
    "cfg = Config(args)\n",
    "\n",
    "model_config = cfg.model_cfg\n",
    "model_config.device_8bit = args.gpu_id\n",
    "model_cls = registry.get_model_class(model_config.arch)\n",
    "model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))\n",
    "\n",
    "vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train\n",
    "vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)\n",
    "chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id))\n",
    "print('Initialization Finished')\n",
    "\n",
    "print('Intializing Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee9e17-5a23-47dc-ac38-d5096efe027b",
   "metadata": {},
   "source": [
    "## Testing Example Image Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c999b-2db6-4dc8-8e92-00b5891163aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the example image file path \n",
    "\n",
    "minigpt4_example_img_path = '' \n",
    "minigpt4_example_img_results = []\n",
    "\n",
    "prompt = \"Please desribe the image\"\n",
    "\n",
    "for i in range(5):\n",
    "    minigpt4_example_img_results.append(ask_model(chat, minigpt4_example_img_path, prompt, []))\n",
    "\n",
    "minigpt4_example_img_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4d33de-99d4-464f-b8b5-66b3af15db89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "minigpt4_example_img_results_df = pd.DataFrame(minigpt4_example_img_results)\n",
    "minigpt4_example_img_results_df.to_csv('minigpt4_example_img_consistency_test_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e46591-fb5b-4af9-bc48-7744cc4a2ee7",
   "metadata": {},
   "source": [
    "## Testing Eye Image Consistency "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a62ddb-d8f5-4157-9043-db3c12366d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "minigpt4_eye_img_path = '' \n",
    "minigpt4_eye_img_results = []\n",
    "\n",
    "prompt = \"Please diagnose the image as either glaucomatous or normal\"\n",
    "\n",
    "for i in range(5):\n",
    "    minigpt4_example_img_results.append(ask_model(chat, minigpt4_eye_img_path, prompt, []))\n",
    "\n",
    "minigpt4_eye_img_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff747af-13f1-4710-8c94-a58ceec99440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "minigpt4_eye_img_results_df = pd.DataFrame(minigpt4_eye_img_results)\n",
    "minigpt4_eye_img_results_df.to_csv('minigpt4_eye_img_consistency_test_results.csv')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
