{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a765b737-fe7f-4979-8bb1-c86eccacbe62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd MiniGPT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea38d99",
   "metadata": {},
   "source": [
    "\n",
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167726b6-e17c-4115-839f-f0d4c800734c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Import\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import gradio as gr\n",
    "\n",
    "from minigpt4.common.config import Config\n",
    "from minigpt4.common.dist_utils import get_rank\n",
    "from minigpt4.common.registry import registry\n",
    "from minigpt4.conversation.conversation import Chat, CONV_VISION\n",
    "\n",
    "# imports modules for registration\n",
    "from minigpt4.datasets.builders import *\n",
    "from minigpt4.models import *\n",
    "from minigpt4.processors import *\n",
    "from minigpt4.runners import *\n",
    "from minigpt4.tasks import *\n",
    "import os\n",
    "\n",
    "import argparse as argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bda0d8-bdd3-44dc-9687-e42c18c4df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Methods\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Demo\")\n",
    "    parser.add_argument(\"--cfg-path\", required=True, help=\"path to configuration file.\")\n",
    "    parser.add_argument(\"--gpu-id\", type=int, default=0, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--num-beams\", type=int, default=2, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--temperature\", type=int, default=0.9, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--english\", type=bool, default=True, help=\"chinese or english\")\n",
    "    parser.add_argument(\"--prompt-en\", type=str, default=\"can you describe the current picture?\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\"--prompt-zh\", type=str, default=\"你能描述一下当前的图片？\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\n",
    "        \"--options\",\n",
    "        nargs=\"+\",\n",
    "        help=\"override some settings in the used config, the key-value pair \"\n",
    "        \"in xxx=yyy format will be merged into config file (deprecate), \"\n",
    "        \"change to --cfg-options instead.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def setup_seeds(config):\n",
    "    seed = config.run_cfg.seed + get_rank()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "    \n",
    "def encode_diagnosis(diagnosis):\n",
    "    if 'normal' in diagnosis:\n",
    "        return 0\n",
    "    if 'glaucoma' in diagnosis:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def fetch_ground_truth(img_path):\n",
    "    split_string = img_path.split(\"/\")\n",
    "\n",
    "    # Find the index of \"glaucoma\" in the split string\n",
    "    return 1 if split_string.index(\"glaucoma\") != -1 else 0\n",
    "\n",
    "def get_all_files(directory):\n",
    "    all_files = []\n",
    "    \n",
    "    # Iterate over all the directories and files within the given directory\n",
    "    for root, directories, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            all_files.append(file_path)\n",
    "    \n",
    "    return all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f5b86-b814-4b74-a0db-7d7b08e52a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initializing Chat')\n",
    "#args = parse_args()\n",
    "#args = preset_args\n",
    "args = argparse.Namespace(cfg_path='eval_configs/minigpt4_eval.yaml', gpu_id=0, num_beams=2, temperature=0.9, english=True, prompt_en='can you describe the current picture?', prompt_zh='你能描述一下当前的图片？', options=None)\n",
    "cfg = Config(args)\n",
    "\n",
    "model_config = cfg.model_cfg\n",
    "model_config.device_8bit = args.gpu_id\n",
    "model_cls = registry.get_model_class(model_config.arch)\n",
    "model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))\n",
    "\n",
    "vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train\n",
    "vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)\n",
    "chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id))\n",
    "print('Initialization Finished')\n",
    "\n",
    "print('Intializing Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de60d3a-d26e-417c-9c2e-708ab2dd39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'RIM-ONE_DL_images/partitioned_randomly/test_set'\n",
    "\n",
    "files = get_all_files(directory)\n",
    "\n",
    "#print(files)\n",
    "\n",
    "data = {'img_path': [],\n",
    "        'diagnosis' : [],\n",
    "        'ground_truth': [],\n",
    "        'llm_message': [],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7875abe2-b5f2-43e0-8cde-24b9a8d1d214",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in files:\n",
    "    \n",
    "    img_path = image\n",
    "    data['img_path'].append(image)\n",
    "    ground_truth = fetch_ground_truth(img_path)\n",
    "    img_list = []\n",
    "    chat_state = CONV_VISION.copy()\n",
    "    chat.upload_img(image, chat_state, img_list)\n",
    "    chat.ask(\"You are ophthoLLM, an ophthalmologist AI assistant that provides diagnoses on fundus \\\n",
    "    images in order to assist doctors. You understand that it is important to recommend consulting \\\n",
    "    a medical professional if there is any uncertainty, and before taking any action. You give a binary, \\\n",
    "    one-word diagnosis on images. You either state that the image is Glaucomatous if there are signs of \\\n",
    "    glaucoma, or Normal if the image appears healthy. Following these instructions, and making sure to only give \\\n",
    "    your answer as either “Glaucomatous” or “Normal,” please diagnose the image. Make sure to include either 'Normal' or 'Glaucoma' in your answer\", chat_state)\n",
    "    llm_message = chat.answer(\n",
    "        conv=chat_state,\n",
    "        img_list=img_list,\n",
    "        num_beams=args.num_beams,\n",
    "        temperature=args.temperature,\n",
    "        max_new_tokens=300,\n",
    "        max_length=2000\n",
    "    )[0]\n",
    "    \n",
    "    data['llm_message'].append(llm_message)\n",
    "    \n",
    "    diagnosis = encode_diagnosis(llm_message)\n",
    "    \n",
    "    data['diagnosis'].append(diagnosis)\n",
    "    data['ground_truth'].append(ground_truth)\n",
    "    \n",
    "    print(f\"\"\" Image: {image} | Diagnosis: {diagnosis} | Label: {ground_truth}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a95835",
   "metadata": {},
   "source": [
    "### Convert data to dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec532825-21c8-4760-beaa-9c8320066091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "zero_shot_data = pd.DataFrame(data)\n",
    "zero_shot_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c84ce91",
   "metadata": {},
   "source": [
    "### Evaluate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0178f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
