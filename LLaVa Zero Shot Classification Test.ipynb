{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f791468f-57ab-4c8e-8d46-bb0fc524e10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "\n",
    "from llava.constants import IMAGE_TOKEN_INDEX, DEFAULT_IMAGE_TOKEN, DEFAULT_IM_START_TOKEN, DEFAULT_IM_END_TOKEN\n",
    "from llava.conversation import conv_templates, SeparatorStyle\n",
    "from llava.model.builder import load_pretrained_model\n",
    "from llava.utils import disable_torch_init\n",
    "from llava.mm_utils import tokenizer_image_token, get_model_name_from_path, KeywordsStoppingCriteria\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from transformers import TextStreamer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c2917-518f-4963-9676-4fdb0bc039f5",
   "metadata": {},
   "source": [
    "### Define Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2d7192-8199-4b64-a282-06afdfb1bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_file):\n",
    "    if image_file.startswith('http') or image_file.startswith('https'):\n",
    "        response = requests.get(image_file)\n",
    "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "    else:\n",
    "        image = Image.open(image_file).convert('RGB')\n",
    "    return image\n",
    "\n",
    "# get random file methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07002b1b-f7a0-4edd-a9ac-ce7978cbacfb",
   "metadata": {},
   "source": [
    "### Initalize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9d2da-d1ff-4da8-b796-9b6acdf02d30",
   "metadata": {},
   "outputs": [],
   "source": [
    " disable_torch_init()\n",
    "\n",
    "model_name = get_model_name_from_path(args.model_path)\n",
    "tokenizer, model, image_processor, context_len = load_pretrained_model(args.model_path, args.model_base, model_name)\n",
    "\n",
    "if \"v1\" in model_name.lower():\n",
    "    conv_mode = \"llava_v1\"\n",
    "elif \"mpt\" in model_name.lower():\n",
    "    conv_mode = \"mpt\"\n",
    "else:\n",
    "    conv_mode = \"llava_v0\"\n",
    "\n",
    "if args.conv_mode is not None and conv_mode != args.conv_mode:\n",
    "    print('[WARNING] the auto inferred conversation mode is {}, while `--conv-mode` is {}, using {}'.format(conv_mode, args.conv_mode, args.conv_mode))\n",
    "else:\n",
    "    args.conv_mode = conv_mode\n",
    "\n",
    "conv = conv_templates[args.conv_mode].copy()\n",
    "if \"mpt\" in model_name.lower():\n",
    "    roles = ('user', 'assistant')\n",
    "else:\n",
    "    roles = conv.roles"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
