{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b814cdf3-6a12-4bad-8897-5a95fa4da93f",
   "metadata": {},
   "source": [
    "# MiniGPT-4\n",
    "MiniGPT-4 13B parameter version Zero Shot Classfication with 3 different prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d84e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd MiniGPT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebdf56b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd8d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import gradio as gr\n",
    "\n",
    "from minigpt4.common.config import Config\n",
    "from minigpt4.common.dist_utils import get_rank\n",
    "from minigpt4.common.registry import registry\n",
    "from minigpt4.conversation.conversation import Chat, CONV_VISION\n",
    "\n",
    "# imports modules for registration\n",
    "from minigpt4.datasets.builders import *\n",
    "from minigpt4.models import *\n",
    "from minigpt4.processors import *\n",
    "from minigpt4.runners import *\n",
    "from minigpt4.tasks import *\n",
    "import os\n",
    "\n",
    "import argparse as argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829367fe",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c6298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description=\"Demo\")\n",
    "    parser.add_argument(\"--cfg-path\", required=True, help=\"path to configuration file.\")\n",
    "    parser.add_argument(\"--gpu-id\", type=int, default=0, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--num-beams\", type=int, default=2, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--temperature\", type=int, default=0.9, help=\"specify the gpu to load the model.\")\n",
    "    parser.add_argument(\"--english\", type=bool, default=True, help=\"chinese or english\")\n",
    "    parser.add_argument(\"--prompt-en\", type=str, default=\"can you describe the current picture?\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\"--prompt-zh\", type=str, default=\"你能描述一下当前的图片？\", help=\"Can you describe the current picture?\")\n",
    "    parser.add_argument(\n",
    "        \"--options\",\n",
    "        nargs=\"+\",\n",
    "        help=\"override some settings in the used config, the key-value pair \"\n",
    "        \"in xxx=yyy format will be merged into config file (deprecate), \"\n",
    "        \"change to --cfg-options instead.\",\n",
    "    )\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "\n",
    "def setup_seeds(config):\n",
    "    seed = config.run_cfg.seed + get_rank()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    cudnn.benchmark = False\n",
    "    cudnn.deterministic = True\n",
    "\n",
    "\n",
    "### fix this method since it's not completely accurate \n",
    "def encode_diagnosis(diagnosis):\n",
    "    # could add: if contains glaucomatous and normal, then only look at first sentence\n",
    "    \n",
    "    if 'glaucomatous' in diagnosis.lower():\n",
    "        return 1\n",
    "    if 'normal' in diagnosis.lower():\n",
    "        return 0\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def fetch_ground_truth(img_path):\n",
    "    split_string = img_path.split(\"/\")\n",
    "\n",
    "    # Find the index of \"glaucoma\" in the split string\n",
    "    try:\n",
    "        split_string.index(\"glaucoma\")\n",
    "        return 1\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def get_all_files(directory):\n",
    "    all_files = []\n",
    "    \n",
    "    # Iterate over all the directories and files within the given directory\n",
    "    for root, directories, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            all_files.append(file_path)\n",
    "    \n",
    "    return all_files\n",
    "\n",
    "def ask_model(chat_state, image, prompt, img_list):\n",
    "    chat_state.upload_img(image, chat_state, img_list)\n",
    "    chat_state.ask(prompt, chat_state)\n",
    "    llm_message = chat.answer(\n",
    "        conv=chat_state,\n",
    "        img_list=img_list,\n",
    "        num_beams=args.num_beams,\n",
    "        temperature=args.temperature,\n",
    "        max_new_tokens=300,\n",
    "        max_length=2000\n",
    "    )[0]\n",
    "    return llm_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815fb7d3",
   "metadata": {},
   "source": [
    "### Initialize the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da58682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Initializing Chat')\n",
    "#args = parse_args()\n",
    "#args = preset_args\n",
    "args = argparse.Namespace(cfg_path='eval_configs/minigpt4_eval.yaml', gpu_id=0, num_beams=2, temperature=0.9, english=True, prompt_en='can you describe the current picture?', prompt_zh='你能描述一下当前的图片？', options=None)\n",
    "cfg = Config(args)\n",
    "\n",
    "model_config = cfg.model_cfg\n",
    "model_config.device_8bit = args.gpu_id\n",
    "model_cls = registry.get_model_class(model_config.arch)\n",
    "model = model_cls.from_config(model_config).to('cuda:{}'.format(args.gpu_id))\n",
    "\n",
    "vis_processor_cfg = cfg.datasets_cfg.cc_sbu_align.vis_processor.train\n",
    "vis_processor = registry.get_processor_class(vis_processor_cfg.name).from_config(vis_processor_cfg)\n",
    "chat = Chat(model, vis_processor, device='cuda:{}'.format(args.gpu_id))\n",
    "print('Initialization Finished')\n",
    "\n",
    "print('Intializing Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a63245",
   "metadata": {},
   "source": [
    "### Set the directory of the test images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d199851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "directory = 'RIM-ONE_DL_images/partitioned_randomly/test_set'\n",
    "\n",
    "files = get_all_files(directory)\n",
    "random.shuffle(files)\n",
    "\n",
    "#print(files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d2e16",
   "metadata": {},
   "source": [
    "## Run Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb15de",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"Please diagnose the fundus image as either glaucomatous or normal.\"\n",
    "prompt2 = \"\"\"You are ophthoLLM, an ophthalmologist AI assistant that provides diagnoses on fundus \n",
    "    images in order to assist doctors. You understand that it is important to recommend consulting \n",
    "    a medical professional if there is any uncertainty, and before taking any action. You give a binary, \n",
    "    one-word diagnosis on images. You either state that the image is Glaucomatous if there are signs of \n",
    "    glaucoma, or Normal if the image appears healthy. Following these instructions, and making sure to only give \n",
    "    your answer as either “Glaucomatous” or “Normal,” please diagnose the image. Make sure to include either 'Normal' or 'Glaucoma' in your answer.\"\"\"\n",
    "\n",
    "prompt3 = \"\"\"You are OphthoLLM, an ophthalmology expert AI that diagnosis Glaucoma. You have been provided a fundus image. \n",
    "\n",
    "Here are some guidelines for diagnosing Glaucoma using a fundus image. \n",
    "\n",
    "Optic Disc Size: The size of the optic disc should be evaluated, as variations can be a normal characteristic. However, an unusually small or large optic disc may indicate specific conditions or risk factors.\n",
    "\n",
    "Cup-to-Disc Ratio: The cup-to-disc ratio measures the size of the cup (the depression in the center of the optic nerve head) relative to the size of the entire optic disc. An increased cup-to-disc ratio may suggest glaucomatous damage.\n",
    "\n",
    "Cup Shape: The shape of the cup should be observed, as an asymmetric or vertically elongated cup can be an indication of glaucoma.\n",
    "\n",
    "Optic Disc Rim: The appearance of the neuroretinal rim, which surrounds the cup, is assessed. In glaucoma, this rim tends to thin and become pale or grayish.\n",
    "\n",
    "Rim Notching: Notching or notches in the neuroretinal rim, particularly in the inferior and superior regions, can be a characteristic sign of glaucoma.\n",
    "\n",
    "Disc Hemorrhages: Presence of hemorrhages, small bleeding spots, at or around the optic nerve head may indicate glaucomatous damage.\n",
    "\n",
    "Nerve Fiber Layer Defects: The doctor will look for thinning or gaps in the retinal nerve fiber layer (RNFL) around the optic nerve head, which is a common early sign of glaucoma.\n",
    "\n",
    "Vascular Changes: Changes in the blood vessels, such as vascular narrowing, crossing defects, or bayoneting, may suggest glaucoma or other optic nerve disorders.\n",
    "\n",
    "Optic Disc Color: The color of the optic nerve head is assessed, and any abnormal discoloration, such as pallor or hyperemia, may raise suspicion of optic nerve damage.\n",
    "Peripapillary Atrophy: Doctors will look for areas of atrophy (thinning) of the retinal pigment epithelium around the optic disc, which can be associated with glaucoma.\n",
    "\n",
    "Optic Nerve Head Excavation: The depth of the optic nerve head excavation or the cup depth is evaluated, as increased cupping can indicate glaucomatous damage.\n",
    "\n",
    "Presence of Drusen: In elderly patients, the presence of drusen, small yellowish deposits in the optic disc, should be noted, as they may mimic glaucomatous changes.\n",
    "\n",
    "Please answer my questions.\n",
    "\"\"\"\n",
    "\n",
    "prompts = [prompt1, prompt2, prompt3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eea8b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for num, prompt in enumerate(prompts):\n",
    "    data = {'img_path': [],\n",
    "            'diagnosis' : [],\n",
    "            'ground_truth': [],\n",
    "            'llm_message': [],\n",
    "            }\n",
    "    for image in files:\n",
    "        data['img_path'].append(image)\n",
    "        ground_truth = fetch_ground_truth(image)\n",
    "        chat_state = CONV_VISION.copy()\n",
    "        llm_message = ask_model(chat_state, prompt, image, [])\n",
    "        data['llm_message'].append(llm_message)\n",
    "        diagnosis = encode_diagnosis(llm_message)\n",
    "        data['diagnosis'].append(diagnosis)\n",
    "        data['ground_truth'].append(ground_truth)\n",
    "        print(f\"\"\" Image: {image} | Diagnosis: {diagnosis} | Label: {ground_truth} | LLM: {llm_message}\"\"\")\n",
    "    \n",
    "   \n",
    "    data_output_dir = \"zero_shot_data_prompt\"+str(num+1)+\".csv\"\n",
    "    zero_shot_data = pd.DataFrame(data)\n",
    "    zero_shot_data.to_csv(data_output_dir)\n",
    "    zero_shot_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a7a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "all_metrics = []\n",
    "\n",
    "for num in range(3):\n",
    "    data_dir = \"zero_shot_data_prompt\"+str(num+1)+\".csv\"\n",
    "    zero_shot_data = pd.read_csv(data_dir)\n",
    "    \n",
    "    y_pred = zero_shot_data['diagnosis']\n",
    "    y_true = zero_shot_data['ground_truth']\n",
    "\n",
    "    metrics.ConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n",
    "    plt.show()\n",
    "    metrics.PrecisionRecallDisplay.from_predictions(y_true, y_pred)\n",
    "    plt.show()\n",
    "\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    specificity = tn / (tn+fp)\n",
    "\n",
    "    prec = tp/(tp+fp)\n",
    "\n",
    "    rec = tp/(tp+fn)\n",
    "\n",
    "    npv = tn/(fn + tn)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "\n",
    "    precision, recall, _ = metrics.precision_recall_curve(y_true, y_pred)\n",
    "    prc = metrics.PrecisionRecallDisplay(precision=precision, recall=recall)\n",
    "    prc.plot()\n",
    "    plt.show()\n",
    "\n",
    "    metrics.RocCurveDisplay.from_predictions(y_true, y_pred)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    roc = metrics.roc_curve(y_true, y_pred)\n",
    "    auroc = metrics.roc_auc_score(y_true, y_pred)\n",
    "    auprc = metrics.average_precision_score(y_true, y_pred)\n",
    "\n",
    "    f1_score = metrics.f1_score(y_true, y_pred)\n",
    "\n",
    "    zero_shot_metrics = {\n",
    "                        'name' : 'prompt '+str(num+1),\n",
    "                        'accuracy': accuracy,\n",
    "                        'precision': prec,\n",
    "                        'recall': rec,\n",
    "                        'auroc': auroc,\n",
    "                        'auprc': auprc,\n",
    "                        'f1_score': f1_score,\n",
    "                        'tn:': tn,\n",
    "                        'fp': fp,\n",
    "                        'fn': fn,\n",
    "                        'tp': tp,\n",
    "                        'negative predictive value': npv,\n",
    "                        'specificity': specificity,\n",
    "                        }\n",
    "\n",
    "    all_metrics.append(zero_shot_metrics)\n",
    "\n",
    "    zero_shot_metrics_df = pd.DataFrame(zero_shot_metrics, index=[0])\n",
    "    metrics_output_dir = \"zero_shot_metrics_prompt\"+str(num+1)+\".csv\"\n",
    "    metrics_output_dir.to_csv(metrics_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff470d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
